{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from build_polynomial import build_poly\n",
    "from plots import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "79923\n",
      "61985\n",
      "40333\n",
      "17759\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = 'C:/Users/Sepideh/Desktop/MA1/ML/Project_1/ML-Project/data/train/train.csv' # TODO: download train data and supply path here \n",
    "y, raw_tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "x_train, y_train, ids_train, x_test, y_test, ids_test = split_data(raw_tX, y, ids, 0.8)\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "raw_tX = np.array(raw_tX)\n",
    "\n",
    "jet0_indx, y_0, data_0, ids_0 = partition(y_train, x_train, ids_train, 0)\n",
    "jet1_indx, y_1, data_1, ids_1 = partition(y_train, x_train, ids_train, 1)\n",
    "jet2_indx, y_2, data_2, ids_2 = partition(y_train, x_train, ids_train, 2)\n",
    "jet3_indx, y_3, data_3, ids_3 = partition(y_train, x_train, ids_train, 3)\n",
    "\n",
    "#ata_0, _= replace_empty(data_0)\n",
    "#data_1, _= replace_empty(data_1)\n",
    "#data_2, _= replace_empty(data_2)\n",
    "#data_3, _= replace_empty(data_3)\n",
    "\n",
    "#data_0 = remove_outliers(data_0)\n",
    "#data_1 = remove_outliers(data_1)\n",
    "#data_2 = remove_outliers(data_2)\n",
    "#data_3 = remove_outliers(data_3)\n",
    "tX_0 = preprocessing(data_0)\n",
    "tX_1 = preprocessing(data_1)\n",
    "tX_2 = preprocessing(data_2)\n",
    "tX_3 = preprocessing(data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Training Losses : [[0.35307808 0.34896772 0.34441942 0.34103478 0.34054054 0.34161036\n",
      "  0.34289915 0.34521396 0.35195195 0.36285035]\n",
      " [0.35307808 0.34896772 0.34441942 0.34103478 0.34054054 0.34161036\n",
      "  0.34289915 0.34521396 0.35195195 0.36285035]\n",
      " [0.35307808 0.34896772 0.34441942 0.34103478 0.34054054 0.34161036\n",
      "  0.34289915 0.34521396 0.35195195 0.36285035]\n",
      " [0.35307808 0.34896772 0.34441942 0.34103478 0.34054054 0.34161036\n",
      "  0.34289915 0.34521396 0.35195195 0.36285035]\n",
      " [0.35307808 0.34896772 0.34441942 0.34103478 0.34054054 0.34161036\n",
      "  0.34289915 0.34521396 0.35195195 0.36285035]]\n",
      "Testing Losses : [[0.35432933 0.34987487 0.34622122 0.34346847 0.34244244 0.34351852\n",
      "  0.34419419 0.34637137 0.3523023  0.36346346]\n",
      " [0.35432933 0.34987487 0.34622122 0.34346847 0.34244244 0.34351852\n",
      "  0.34419419 0.34637137 0.3523023  0.36346346]\n",
      " [0.35432933 0.34987487 0.34622122 0.34346847 0.34244244 0.34351852\n",
      "  0.34419419 0.34637137 0.3523023  0.36346346]\n",
      " [0.35432933 0.34987487 0.34622122 0.34346847 0.34244244 0.34351852\n",
      "  0.34419419 0.34637137 0.3523023  0.36346346]\n",
      " [0.35432933 0.34987487 0.34622122 0.34346847 0.34244244 0.34351852\n",
      "  0.34419419 0.34637137 0.3523023  0.36346346]]\n",
      "0.0016681005372000592\n",
      "2\n",
      "0.3833439685697484\n"
     ]
    }
   ],
   "source": [
    "def k_fold_cross_validation(y, tx, k_fold):\n",
    "    seed = 1\n",
    "    degrees = np.arange(2,7) \n",
    "    lambdas = np.logspace(-5, 0, 10) #lambda changing from 10^(-4) to 1\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = np.zeros((len(degrees), len(lambdas)))\n",
    "    rmse_te = np.zeros((len(degrees), len(lambdas)))\n",
    "  \n",
    "    for i_d,d in enumerate(degrees):\n",
    "        print(i_d)\n",
    "        for i_l,l in enumerate(lambdas):\n",
    "            tr_loss = []\n",
    "            te_loss = []\n",
    "            for k in range(k_fold):\n",
    "                l_tr, l_te = ridge_reg_cross_validation(y, tx, k_indices, k, l, d)\n",
    "                tr_loss.append(l_tr)\n",
    "                te_loss.append(l_te)\n",
    "            \n",
    "            rmse_tr[i_d][i_l] = np.mean(tr_loss)\n",
    "            rmse_te[i_d][i_l] = np.mean(te_loss)\n",
    "        \n",
    "    opt_i = np.argmin(rmse_te)\n",
    "    opt_d = opt_i // len(lambdas)\n",
    "    opt_l = opt_i % len(lambdas)\n",
    "    lambda_ = lambdas[opt_l]\n",
    "    degree = degrees[opt_d]\n",
    "    \n",
    "    #tx = build_poly(tx, degree)\n",
    "    #weights, _ = ridge_regression(y, tx, lambda_)\n",
    "    #cross_validation_visualization(lambdas, rmse_tr, rmse_te, \"ridge_regression_cross_validation: Lambda Tuning\", \"lambda\")\n",
    "    print(\"Training Losses : {rmse_tr}\".format(rmse_tr=rmse_tr))\n",
    "    print(\"Testing Losses : {rmse_te}\".format(rmse_te=rmse_te))\n",
    "    return lambda_, degree\n",
    "    \n",
    "lambda_0, degree_0 = k_fold_cross_validation(y_0, tX_0, 5)\n",
    "tX_0 = build_poly(tX_0, degree_0)\n",
    "weights_0,_ = ridge_regression(y_0, tX_0, lambda_0)\n",
    "loss_0 = compute_loss(y_0, tX_0, weights_0)\n",
    "print(lambda_0)\n",
    "print(degree_0)\n",
    "print(loss_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Training Losses : [[0.53209647 0.52870049 0.52332822 0.51750423 0.5135194  0.5133258\n",
      "  0.51615713 0.52777285 0.55796564 0.60954263]\n",
      " [0.53209647 0.52870049 0.52332822 0.51750423 0.5135194  0.5133258\n",
      "  0.51615713 0.52777285 0.55796564 0.60954263]\n",
      " [0.53209647 0.52870049 0.52332822 0.51750423 0.5135194  0.5133258\n",
      "  0.51615713 0.52777285 0.55796564 0.60954263]\n",
      " [0.53209647 0.52870049 0.52332822 0.51750423 0.5135194  0.5133258\n",
      "  0.51615713 0.52777285 0.55796564 0.60954263]\n",
      " [0.53209647 0.52870049 0.52332822 0.51750423 0.5135194  0.5133258\n",
      "  0.51615713 0.52777285 0.55796564 0.60954263]]\n",
      "Testing Losses : [[0.5363233  0.53251593 0.52690167 0.52190046 0.51686698 0.516383\n",
      "  0.51767363 0.52874082 0.55965153 0.61040574]\n",
      " [0.5363233  0.53251593 0.52690167 0.52190046 0.51686698 0.516383\n",
      "  0.51767363 0.52874082 0.55965153 0.61040574]\n",
      " [0.5363233  0.53251593 0.52690167 0.52190046 0.51686698 0.516383\n",
      "  0.51767363 0.52874082 0.55965153 0.61040574]\n",
      " [0.5363233  0.53251593 0.52690167 0.52190046 0.51686698 0.516383\n",
      "  0.51767363 0.52874082 0.55965153 0.61040574]\n",
      " [0.5363233  0.53251593 0.52690167 0.52190046 0.51686698 0.516383\n",
      "  0.51767363 0.52874082 0.55965153 0.61040574]]\n",
      "0.005994842503189409\n",
      "2\n",
      "0.549165120593692\n"
     ]
    }
   ],
   "source": [
    "lambda_1, degree_1 = k_fold_cross_validation(y_1, tX_1, 5)\n",
    "tX_1 = build_poly(tX_1, degree_1)\n",
    "weights_1,_ = ridge_regression(y_1, tX_1, lambda_1)\n",
    "loss_1 = compute_loss(y_1, tX_1, weights_1)\n",
    "print(lambda_1)\n",
    "print(degree_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Training Losses : [[0.51183982 0.51253409 0.51347632 0.51584428 0.52041904 0.53001488\n",
      "  0.55061989 0.58984627 0.64078849 0.68910241]\n",
      " [0.51183982 0.51253409 0.51347632 0.51584428 0.52041904 0.53001488\n",
      "  0.55061989 0.58984627 0.64078849 0.68910241]\n",
      " [0.51183982 0.51253409 0.51347632 0.51584428 0.52041904 0.53001488\n",
      "  0.55061989 0.58984627 0.64078849 0.68910241]\n",
      " [0.51183982 0.51253409 0.51347632 0.51584428 0.52041904 0.53001488\n",
      "  0.55061989 0.58984627 0.64078849 0.68910241]\n",
      " [0.51183982 0.51253409 0.51347632 0.51584428 0.52041904 0.53001488\n",
      "  0.55061989 0.58984627 0.64078849 0.68910241]]\n",
      "Testing Losses : [[0.52060501 0.52040665 0.52149764 0.52377882 0.52809323 0.53538309\n",
      "  0.55536821 0.59429705 0.64269774 0.69050335]\n",
      " [0.52060501 0.52040665 0.52149764 0.52377882 0.52809323 0.53538309\n",
      "  0.55536821 0.59429705 0.64269774 0.69050335]\n",
      " [0.52060501 0.52040665 0.52149764 0.52377882 0.52809323 0.53538309\n",
      "  0.55536821 0.59429705 0.64269774 0.69050335]\n",
      " [0.52060501 0.52040665 0.52149764 0.52377882 0.52809323 0.53538309\n",
      "  0.55536821 0.59429705 0.64269774 0.69050335]\n",
      " [0.52060501 0.52040665 0.52149764 0.52377882 0.52809323 0.53538309\n",
      "  0.55536821 0.59429705 0.64269774 0.69050335]]\n",
      "3.5938136638046256e-05\n",
      "2\n",
      "0.46448317754692187\n"
     ]
    }
   ],
   "source": [
    "lambda_2, degree_2 = k_fold_cross_validation(y_2, tX_2, 5)\n",
    "tX_2 = build_poly(tX_2, degree_2)\n",
    "weights_2,_ = ridge_regression(y_2, tX_2, lambda_2)\n",
    "loss_2 = compute_loss(y_2, tX_2, weights_2)\n",
    "print(lambda_2)\n",
    "print(degree_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Training Losses : [[0.48949592 0.48848212 0.48645452 0.48194875 0.47682343 0.46862856\n",
      "  0.46440439 0.47288088 0.49498733 0.52748522]\n",
      " [0.48949592 0.48848212 0.48645452 0.48194875 0.47682343 0.46862856\n",
      "  0.46440439 0.47288088 0.49498733 0.52748522]\n",
      " [0.48949592 0.48848212 0.48645452 0.48194875 0.47682343 0.46862856\n",
      "  0.46440439 0.47288088 0.49498733 0.52748522]\n",
      " [0.48949592 0.48848212 0.48645452 0.48194875 0.47682343 0.46862856\n",
      "  0.46440439 0.47288088 0.49498733 0.52748522]\n",
      " [0.48949592 0.48848212 0.48645452 0.48194875 0.47682343 0.46862856\n",
      "  0.46440439 0.47288088 0.49498733 0.52748522]]\n",
      "Testing Losses : [[0.50813855 0.50678682 0.50442129 0.50002816 0.49687412 0.48572233\n",
      "  0.48076598 0.48414531 0.504196   0.53111799]\n",
      " [0.50813855 0.50678682 0.50442129 0.50002816 0.49687412 0.48572233\n",
      "  0.48076598 0.48414531 0.504196   0.53111799]\n",
      " [0.50813855 0.50678682 0.50442129 0.50002816 0.49687412 0.48572233\n",
      "  0.48076598 0.48414531 0.504196   0.53111799]\n",
      " [0.50813855 0.50678682 0.50442129 0.50002816 0.49687412 0.48572233\n",
      "  0.48076598 0.48414531 0.504196   0.53111799]\n",
      " [0.50813855 0.50678682 0.50442129 0.50002816 0.49687412 0.48572233\n",
      "  0.48076598 0.48414531 0.504196   0.53111799]]\n",
      "0.021544346900318846\n",
      "2\n",
      "0.5065600540570978\n"
     ]
    }
   ],
   "source": [
    "lambda_3, degree_3 = k_fold_cross_validation(y_3, tX_3, 5)\n",
    "tX_3 = build_poly(tX_3, degree_3)\n",
    "weights_3,_ = ridge_regression(y_3, tX_3, lambda_3)\n",
    "loss_3 = compute_loss(y_3, tX_3, weights_3)\n",
    "print(lambda_3)\n",
    "print(degree_3)\n",
    "print(loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_0 = build_poly(tX_0, 2)\n",
    "tX_1 = build_poly(tX_1, 2)\n",
    "tX_2 = build_poly(tX_2, 2)\n",
    "tX_3 = build_poly(tX_3, 2)\n",
    "\n",
    "\n",
    "lambda_ = 0.000774263682681127\n",
    "weights_0,_ = ridge_regression(y_0, tX_0, lambda_)\n",
    "weights_1,_ = ridge_regression(y_1, tX_1, lambda_)\n",
    "weights_2,_ = ridge_regression(y_2, tX_2, lambda_)\n",
    "weights_3,_ = ridge_regression(y_3, tX_3, lambda_)\n",
    "\n",
    "\n",
    "#weights_0,_ = least_squares(y_0, tX_0)\n",
    "#weights_1,_ = least_squares(y_1, tX_1)\n",
    "#weights_2,_ = least_squares(y_2, tX_2)\n",
    "#weights_3,_ = least_squares(y_3, tX_3)\n",
    "\n",
    "loss_0 = compute_loss(y_0, tX_0, weights_0)\n",
    "loss_1 = compute_loss(y_1, tX_1, weights_1)\n",
    "loss_2 = compute_loss(y_2, tX_2, weights_2)\n",
    "loss_3 = compute_loss(y_3, tX_3, weights_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238,)\n",
      "227458\n",
      "175338\n",
      "114648\n",
      "50794\n",
      "(568238,)\n",
      "0.3039377866316579\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = 'C:/Users/Sepideh/Desktop/MA1/ML/Project_1/ML-Project/data/test/test.csv' # TODO: download train data and supply path here \n",
    "y_test, x_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(ids_test.shape)\n",
    "jet0_indx, y_0, data_0, ids_0 = partition(y_test, x_test, ids_test, 0)\n",
    "jet1_indx, y_1, data_1, ids_1 = partition(y_test, x_test, ids_test, 1)\n",
    "jet2_indx, y_2, data_2, ids_2 = partition(y_test, x_test, ids_test, 2)\n",
    "jet3_indx, y_3, data_3, ids_3 = partition(y_test, x_test, ids_test, 3)\n",
    "\n",
    "tX_0 = preprocessing(data_0)\n",
    "tX_1 = preprocessing(data_1)\n",
    "tX_2 = preprocessing(data_2)\n",
    "tX_3 = preprocessing(data_3)\n",
    "\n",
    "\n",
    "tX_0 = build_poly(tX_0, 2)\n",
    "tX_1 = build_poly(tX_1, 2)\n",
    "tX_2 = build_poly(tX_2, 2)\n",
    "tX_3 = build_poly(tX_3, 2)\n",
    "\n",
    "y_pred_0 = predict_labels(weights_0, tX_0)\n",
    "y_pred_1 = predict_labels(weights_1, tX_1)\n",
    "y_pred_2 = predict_labels(weights_2, tX_2)\n",
    "y_pred_3 = predict_labels(weights_3, tX_3)\n",
    "\n",
    "ids_test = np.concatenate((ids_0, ids_1))\n",
    "ids_test = np.concatenate((ids_test, ids_2))\n",
    "ids_test = np.concatenate((ids_test, ids_3))\n",
    "print(ids_test.shape)\n",
    "\n",
    "y_pred = np.concatenate((y_pred_0, y_pred_1))\n",
    "y_pred = np.concatenate((y_pred, y_pred_2))\n",
    "y_pred = np.concatenate((y_pred, y_pred_3))\n",
    "\n",
    "\n",
    "sorted_indx = np.argsort(ids_test)\n",
    "\n",
    "y = np.concatenate((y_0, y_1))\n",
    "y = np.concatenate((y, y_2))\n",
    "y = np.concatenate((y, y_3))\n",
    "\n",
    "OUTPUT_PATH = 'C:/Users/Sepideh/Desktop/MA1/ML/Project_1/ML-Project/data/output/output.csv' # TODO: fill in desired name of output file for submission\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "ids_test = ids_test[sorted_indx]\n",
    "y_pred = y_pred[sorted_indx]\n",
    "y = y[sorted_indx]\n",
    "acc = compute_accuracy(y_pred, y)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80106\n"
     ]
    }
   ],
   "source": [
    "f1 = compute_F1(y_pred, y)\n",
    "\n",
    "#print(y[y_n!=1 for y_n in y])\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
